{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE\n",
    "This file deals with RMSE\n",
    "\n",
    "It is simpler than visualize_emergent.\n",
    "\n",
    "It loads the trajectories for the defined models (model_labels). \n",
    "\n",
    "The trajectories are also all combined into \"all_multi_trajs\" and \"all_single_trajs\", which is how we compute the average performance across models. We concatenate the N scenes (for example 200) generated from each model, resulting in N * N_models scenes in those combined trajectories (6 for the default case).\n",
    "\n",
    "The RMSE are actually computed in the environment, so it is pretty straightforward to extract them, with most of the remaining code being for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import utils\n",
    "import visualize_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = [\n",
    "    'multiagent_curr_1_fine',\n",
    "    'multiagent_curr_2_fine',\n",
    "    'multiagent_curr_3_fine',\n",
    "    'multiagent_rails_col_1_fine',\n",
    "    'multiagent_rails_col_2_fine',\n",
    "    'multiagent_rails_col_3_fine'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_lab_dict = visualize_utils.get_trajs_dict(model_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traj_lab_dict Structure:\n",
    "\n",
    "* for each model, a tuple of (trajectories, labels) that are returned from utils.load_trajs_labels()\n",
    "    \n",
    "    * trajectories is a list \n",
    "    \n",
    "        * there is a list element for each dataset (e.g. i101_750_805, i101_805_815..., so 6 elements)\n",
    "        \n",
    "            * This is determined from the validate run. Each dataset that we generate trajectories for (filenames variable in the main function for validate.py)\n",
    "        \n",
    "        * each list element is an ndarry of shape (T,), where T = number of simulations run. \n",
    "                * This is determined in validate.py, as run_args.n_multiagent_trajs / args.n_envs. For n_trajs = 10000, n_vehs = 100, T = 100.\n",
    "        \n",
    "                * validate.py produces a total of run_args.n_multiagent_trajs trajectories. From each initial sample scene, we simulate 1 trajectory for each agent. Thus, n_vehs trajectories. Therefore, we need to run T simulations. \n",
    "         \n",
    "            * each item in the array is a dictionary, of trajectory 'characteristics'\n",
    "            \n",
    "               * a trajectory component is something like, observations, actions:\n",
    "           \n",
    "                   * dict_keys(['rewards', 'rmse_t', 'prev_action', 'x', 'observations', 'mean', 'is_colliding', 'actions', 'y', 'log_std', 'rmse_vel', 'rmse_pos', 'phi', 's'])\n",
    "                  \n",
    "                   * the values are an array of shape (H, N, K), where H = the env_H (length of a trajectory or number of timesteps). N = number of agents. K is a third dimension, for things like observations (for which K=64). For something like rmse_t, K doesn't exist (array of shape (H, N)).\n",
    "                   \n",
    "                   * There is essentially a dictionary for every intial scene that we sampled. \n",
    "    \n",
    "    - labels is a list\n",
    "    \n",
    "        * There is also an element for each dataset, like for trajectories. So, 6 in the default case we have.\n",
    "    \n",
    "            + ['0750am-0805am', '0805am-0820am', '0820am-0835am', '0400-0415', '0500-0515', '0515-0530']\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_multi_trajs = visualize_utils.combine_trajs([traj_lab_dict[model_label][0] for model_label in model_labels if not 'rails' in model_label])\n",
    "all_rails_trajs = visualize_utils.combine_trajs([traj_lab_dict[model_label][0] for model_label in model_labels if 'rails' in model_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trajectories(trajs, length, label='', color='blue', attr='rmse', style='solid'):\n",
    "    rmses = []\n",
    "    for traj in trajs:\n",
    "        if len(traj[attr]) == length:\n",
    "            #print(traj[attr].shape) # 200 x 50\n",
    "            #print(np.mean(traj[attr],axis=1).shape) # 200 x 1\n",
    "            # here we want to simply act as though all of the trajectories are independent. \n",
    "            # We no longer care that they were from the same scene.\n",
    "            for veh_i in range(traj[attr].shape[1]):\n",
    "                rmses.append(traj[attr][:,veh_i])\n",
    "    rmses = np.array(rmses)\n",
    "    mean = np.mean(rmses, axis=0)\n",
    "    bound = np.std(rmses, axis=0) / np.sqrt(len(rmses)) / 2\n",
    "    x = range(len(mean))\n",
    "    plt.fill_between(x, mean - bound, mean + bound, alpha=.4, color=color)\n",
    "    plt.plot(x, mean, c=color, label='mean {}: {:.5f}'.format(attr, np.mean(rmses)), linestyle=style)\n",
    "    plt.xlabel('timesteps')\n",
    "    plt.ylabel(attr)\n",
    "    plt.title(label)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation(trajs, labels, color='blue', length=200, attr='rmse', style='solid'):\n",
    "    trajs = [\n",
    "        trajs[0],\n",
    "        np.concatenate((trajs[1], trajs[2])),\n",
    "        np.concatenate((trajs[3], trajs[4], trajs[5]))\n",
    "    ]\n",
    "    labels = [\n",
    "        labels[0],\n",
    "        labels[1] + ' ' + labels[2],\n",
    "        labels[3] + ' ' + labels[4] + ' ' + labels[4] \n",
    "    ]\n",
    "    for i, traj in enumerate(trajs):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        visualize_trajectories(traj, length, labels[i], attr=attr, color=color, style=style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the below after redefining/reloading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attrs = ['rmse_pos', 'rmse_t', 'rmse_vel', 'is_colliding']\n",
    "colors = {\n",
    "    'multiagent_rails_col_1_fine': 'blue',\n",
    "    'multiagent_rails_col_2_fine': 'red',\n",
    "    'multiagent_rails_col_3_fine': 'magenta',\n",
    "    'multiagent_curr_1_fine': 'blue',\n",
    "    'multiagent_curr_2_fine': 'red',\n",
    "    'multiagent_curr_3_fine': 'magenta',\n",
    "}\n",
    "for i, label in enumerate(model_labels):\n",
    "    style = 'dotted'\n",
    "    if 'multi' in label: style = 'solid'\n",
    "    print(label, colors[label], style)\n",
    "\n",
    "\n",
    "length = 200\n",
    "ngsim_labels = traj_lab_dict[model_labels[0]][1]\n",
    "for attr in attrs:\n",
    "    plt.figure(figsize=(16,4))\n",
    "    for i, label in enumerate(model_labels):\n",
    "        style = 'dotted'\n",
    "        if 'rails' in label: style = 'solid'\n",
    "        plot_validation(traj_lab_dict[label][0], ngsim_labels, \n",
    "                    color=colors[label], attr=attr, style=style, length=length)\n",
    "    plt.savefig(attr + '_rails.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['rmse_pos', 'rmse_t', 'rmse_vel', 'is_colliding']\n",
    "ngsim_labels = traj_lab_dict[model_labels[0]][1]\n",
    "for attr in attrs:\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plot_validation(all_rails_trajs, ngsim_labels, color='black', attr=attr, style='dotted', length=length)\n",
    "    plot_validation(all_multi_trajs, ngsim_labels, color='black', attr=attr, style='solid', length=length)\n",
    "\n",
    "    plt.savefig(attr + 'rails_just_avg.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(trajs, length, attr='rmse'):\n",
    "    rmses = []\n",
    "    for traj in trajs:\n",
    "        if len(traj[attr]) == length:\n",
    "            for veh_i in range(traj[attr].shape[1]):\n",
    "                rmses.append(traj[attr][:,veh_i])\n",
    "    rmses = np.array(rmses)\n",
    "    mean = np.mean(rmses, axis=0)\n",
    "    x = range(len(mean))\n",
    "    return (x, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(trajs, labels, length=200, attr='rmse', name='single'):\n",
    "    trajs = [\n",
    "        trajs[0],\n",
    "        np.concatenate((trajs[1], trajs[2])),\n",
    "        np.concatenate((trajs[3], trajs[4], trajs[5]))\n",
    "    ]\n",
    "    labels = [\n",
    "        labels[0],\n",
    "        labels[1] + ' ' + labels[2],\n",
    "        labels[3] + ' ' + labels[4] + ' ' + labels[4] \n",
    "    ]\n",
    "    for i, traj in enumerate(trajs):\n",
    "        (x, mean) = get_means(traj, length, attr=attr)\n",
    "        fn = \"_\".join([name, labels[i].replace(\" \", \"_\"), attr]) + \".csv\"\n",
    "        np.savetxt(fn, (x, mean), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['rmse_pos', 'rmse_t', 'rmse_vel', 'is_colliding']\n",
    "ngsim_labels = traj_lab_dict[model_labels[0]][1]\n",
    "for attr in attrs:\n",
    "    save_data(all_rails_trajs, ngsim_labels, attr=attr, length=length, name='rails_avg')\n",
    "    save_data(all_multi_trajs, ngsim_labels, attr=attr, length=length, name='multi_avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
